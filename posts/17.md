---
title: 뉴스 기사 다중분류하기(DEEP LEARNING with Python)
date: '2023-10-07'
tags: [파이썬,코딩,인공지능,도서]
---  
로이터 뉴스를 46개의 토픽 클래스들로 분류하는 신경망을 만들어보겠습니다. 클래스가 많기 때문에 **다중 분류**에 속합니다.
## 데이터 준비
텍스트 분류를 위해 널리 사용되는 뉴스 기사와 토픽의 집합인 로이터 데이터셋을 사용하겠습니다. 46개의 토픽으로 구성되어 있고 8,982개의 훈련 데이터와 2,246개의 테스트 데이터가 있습니다.
```python
from tensorflow.keras.datasets import reuters

(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words=10000)
```
```python
len(train_data) # 출력: 8982
```
```python
len(test_data) # 출력: 2246
```
**원-핫 인코딩**을 통해 훈련 데이터와 테스트 데이터를 벡터로 변환합니다.
```python
import numpy as np

def vectorize_sequences(sequences, dimension=10000):
    results = np.zeros((len(sequences), dimension))
    for i, sequence in enumerate(sequences):
        for j in sequence:
            results[i,j] = 1
    return results

x_train = vectorize_sequences(train_data)
x_test = vectorize_sequences(test_data)
```
레이블도 원-핫 인코딩을 통해 벡터로 변환하겠습니다. 케라스에서 레이블을 원-핫 인코딩 기법을 사용하여 벡터로 변환시켜주는 내장 함수를 제공합니다. 한 번 써볼게요.
```python
import tensorflow as tf

y_train = tf.keras.utils.to_categorical(train_labels)
y_test = tf.keras.utils.to_categorical(test_labels)
```
## 모델 구성
이제 모델을 구성해보도록 하겠습니다. 토픽이 총 46개이기 때문에 출력층 클래스의 개수는 46개입니다. 46개의 클래스를 구분하기 위해서는 Dense 층의 유닛을 46보다 좀더 큰 값을 줘야 병목현상이 일어나지 않습니다. 넉넉하게 64개의 유닛을 사용해볼게요.
```python
model = tf.keras.Sequential([
    tf.keras.layers.Dense(64, activation="relu"),
    tf.keras.layers.Dense(64, activation="relu"),
    tf.keras.layers.Dense(46, activation="softmax")
])
```
46개의 출력 클래스에 대한 확률 분포를 출력하기 위해 출력층 활성화함수로 softmax를 선택하겠습니다. 그리고 모델이 출력한 확률 분포와 진짜 레이블 분포 사이의 거리를 측정하기 위한 최선의 손실 함수는 categorical_crossentropy입니다.
```python
model.compile(optimizer="rmsprop",
              loss="categorical_crossentropy",
              metrics=["accuracy"])
```
## 훈련 검증
8,982개의 훈련 데이터에서 1000개를 검증 데이터로 사용하겠습니다.
```python
x_val = x_train[:1000]
partial_x_train = x_train[1000:]
y_val = y_train[:1000]
partial_y_train = y_train[1000:]
```
512개의 배치 사이즈, 20 에포크, 검증데이터를 설정하여 훈련을 시킵니다.
```python
history = model.fit(
    partial_x_train,
    partial_y_train,
    epochs=20,
    batch_size=512,
    validation_data=(x_val, y_val)
)
```
학습한 모델의 손실과 정확도 그래프를 그리겠습니다.
```python
import matplotlib.pyplot as plt

loss = history.history["loss"]
val_loss = history.history["val_loss"]
epochs = range(1, len(loss)+1)
plt.plot(epochs, loss, "bo", label="Training loss")
plt.plot(epochs, val_loss, "b", label="Validation loss")
plt.title("Training and validation loss")
plt.xlabel("Epochs")
plt.ylabel("Loss")
plt.legend()
plt.show()
```
![17-1](/images/posts/17-1.png)
_훈련 검증 손실_   

```python
plt.clf()
acc = history.history["accuracy"]
val_acc = history.history["val_accuracy"]
plt.plot(epochs, acc, "bo", label="Training accuracy")
plt.plot(epochs, val_acc, "b", label="Validation accuracy")
plt.title("Training and validation accuracy")
plt.xlabel("Epochs")
plt.ylabel("Loss")
plt.legend()
plt.show()
```
![17-2](/images/posts/17-2.png)
_훈련 검증 정확도_   

그래프를 보니까 9 에포크 이후부터 과대적합을 보이는 것 같습니다. 그래서 9 에포크로 다시 새로운 모델을 학습시키고 테스트 데이터를 평가해보겠습니다.
```python
model = tf.keras.Sequential([
    tf.keras.layers.Dense(64, activation="relu"),
    tf.keras.layers.Dense(64, activation="relu"),
    tf.keras.layers.Dense(46, activation="softmax")
])
model.compile(optimizer="rmsprop",
              loss="categorical_crossentropy",
              metrics=["accuracy"])
model.fit(
    x_train,
    y_train,
    epochs=9,
    batch_size=512)
results = model.evaluate(x_test, y_test)
```
```python
> results
[0.9157146215438843, 0.7951914668083191]
```
약 80%의 정확도를 가진 모델을 완성하였습니다.
## 새로운 데이터에 대해 예측하기
테스트 데이터를 모델에 입력하여 기사들을 46개의 토픽으로의 분류를 예측해보겠습니다.
```python
predictions = model.predict(x_test)
```
```python
> predictions[15,11]
0.9813945
```
```python
> np.argmax(predictions[15])
11
```
16번째 기사의 카테고리는 12 클래스로의 분류를 98%의 확률로 예측하는걸 볼 수 있습니다. 